# Welcome to the Context Check documentation


## What is ContextCheck

ContextCheck aims to provide comprehensive, end-to-end solutions for testing LLM prompts and RAG (Retrieval Augmented Generation) systems. 
Its features range from synthetic questions generation to safeguarding your production system against regressions.

In the IT world, test-driven development is a standard way to build software. ContextCheck brings these practices into AI-assisted applications to help you build your software in a systematic way that ensures the validation and reliability of LLMs and RAG systems.

Simply speaking, ContextCheck:

- Creates a systematic way to validate your RAG systems and/or LLM prompts.

- It can be used as a CLI tool during development and in the CICD pipeline.

- Supports variety of models like OpenAI, Anthropic, Azure, Google, open-source models like Llama either remotely or locally.


## Working with ContextCheck

When working with ContextCheck, you can follow a standard or complete, full-cycle process:

* Standard one can be conceptualized as TDD-like (Test Driven Development) process for RAG/LLM systems. Refer to [Applications and use cases](./getting_started/applications_and_use_cases.md) for details.

* The complete, full-cycle process aims at delivering end-to-end experience that starts from synthetic question generation. Refer to [Full-cycle process](./getting_started/full_cycle_process.md) for details.
