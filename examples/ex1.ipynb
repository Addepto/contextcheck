{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1\n",
    "\n",
    "In this notebook we will present you a simple case of using contextcheck to validate llm responses.\n",
    "\n",
    "We will talk about:\n",
    "- Configuration\n",
    "- Test Scenario\n",
    "- Test Steps\n",
    "- Running the Test Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add optional jinja2 templating section or a remark with a link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install contextcheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextcheck import TestScenario, Executor\n",
    "import rich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send default request\n",
    "\n",
    "Let's initially create a simple yaml that we will use to send a dummy request to OpenAI.\n",
    "\n",
    "*When config is empty then OpenAI's gpt-4o-mini is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_scenario_ex1_progress.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_scenario_ex1_progress.yaml\n",
    "config:\n",
    "\n",
    "steps:\n",
    "   - What is the capital of Poland?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test scenario\n",
    "test_scenario = TestScenario.from_yaml(\"test_scenario_ex1_progress.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">EndpointsEnum.OPENAI:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'test_scenario_ex1_progress.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mdefault_request\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpointsEnum.OPENAI:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'test_scenario_ex1_progress.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize test scenario\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create executor that uses test scenario\n",
    "executor = Executor(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-30 17:21:29.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:29.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mname='What is the capital of Poland?' request=RequestBase(message='What is the capital of Poland?') response=None default_request=RequestBase(message=None) asserts=[] result=None\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:29.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='What is the capital of Poland?'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:30.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='The capital of Poland is Warsaw.' stats=ResponseStats(tokens_request=None, tokens_response=None, tokens_total=None, conn_start_time=27474.283592782, conn_end_time=27475.060895569, conn_duration=0.7773027869989164) choices=[Choice(message={'role': 'assistant', 'content': 'The capital of Poland is Warsaw.'})] config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o-mini', temperature=None, max_tokens=None, provider='ChatOpenAI')\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run all test steps\n",
    "executor.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The capital of Poland is Warsaw.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27474.283592782</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27475.060895569</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7773027869989164</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The capital of Poland is Warsaw.'</span><span style=\"font-weight: bold\">})]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatibleConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">EndpointsEnum.OPENAI:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">asserts</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'test_scenario_ex1_progress.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[32m'The capital of Poland is Warsaw.'\u001b[0m,\n",
       "                \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtokens_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtokens_response\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtokens_total\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m27474\u001b[0m\u001b[1;36m.283592782\u001b[0m,\n",
       "                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m27475\u001b[0m\u001b[1;36m.060895569\u001b[0m,\n",
       "                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.7773027869989164\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'The capital of Poland is Warsaw.'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpointsEnum.OPENAI:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o-mini'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33masserts\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mTestConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mendpoint_under_test\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'test_scenario_ex1_progress.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Once more visualize the test scenario to see the changes\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Poland is Warsaw.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response from llm\n",
    "test_scenario.steps[0].response.message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config update\n",
    "\n",
    "We initially left the config empty, but we can easily populate it with configuration that best fits our needs.\n",
    "\n",
    "For defining the connection to the llm or rag system we use `endpoint_under_test`. For demo purposes we will use one of OpenAI's models which are already implemented by default. For more information please visit [TODO - Link to config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_scenario_ex1_progress.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_scenario_ex1_progress.yaml\n",
    "config:\n",
    "   endpoint_under_test:\n",
    "      kind: openai\n",
    "      model: gpt-4o   \n",
    "\n",
    "steps:\n",
    "   - What is the capital of Poland?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test scenario\n",
    "test_scenario = TestScenario.from_yaml(\"test_scenario_ex1_progress.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">EndpointsEnum.OPENAI:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'test_scenario_ex1_progress.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mdefault_request\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpointsEnum.OPENAI:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'test_scenario_ex1_progress.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize test scenario\n",
    "# Note the change in config from gpt-4o-mini to gpt-4o\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create executor that uses test scenario\n",
    "executor = Executor(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-30 17:21:34.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:34.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mname='What is the capital of Poland?' request=RequestBase(message='What is the capital of Poland?') response=None default_request=RequestBase(message=None) asserts=[] result=None\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:34.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='What is the capital of Poland?'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:35.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='The capital of Poland is Warsaw.' stats=ResponseStats(tokens_request=None, tokens_response=None, tokens_total=None, conn_start_time=27479.252094312, conn_end_time=27479.739785308, conn_duration=0.4876909960003104) choices=[Choice(message={'role': 'assistant', 'content': 'The capital of Poland is Warsaw.'})] config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o', temperature=None, max_tokens=None, provider='ChatOpenAI')\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Poland is Warsaw.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response from llm\n",
    "test_scenario.steps[0].response.message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model's Parameters update\n",
    "\n",
    "In config we can also update the model parameters like temperature, max_tokens etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check this after rebase with contextcheck changes\n",
    "# TODO: I'd add a possibility to transfer parameters through step/request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_scenario_ex1_progress.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_scenario_ex1_progress.yaml\n",
    "config:\n",
    "   endpoint_under_test:\n",
    "      kind: openai\n",
    "      model: gpt-4o-mini\n",
    "      temperature: 2.0\n",
    "      max_tokens: 64\n",
    "\n",
    "steps:\n",
    "   - Write a poem about LLMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test scenario\n",
    "test_scenario = TestScenario.from_yaml(\"test_scenario_ex1_progress.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Write a poem about LLMs'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Write a poem about LLMs'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">EndpointsEnum.OPENAI:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'test_scenario_ex1_progress.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Write a poem about LLMs'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Write a poem about LLMs'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mdefault_request\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mconfig\u001b[0m=\u001b[1;35mTestConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mendpoint_under_test\u001b[0m=\u001b[1;35mEndpointConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpointsEnum.OPENAI:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m2\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[1;36m64\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'test_scenario_ex1_progress.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize test scenario\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create executor that uses test scenario\n",
    "executor = Executor(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-30 17:21:40.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:40.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mname='Write a poem about LLMs' request=RequestBase(message='Write a poem about LLMs') response=None default_request=RequestBase(message=None) asserts=[] result=None\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:40.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='Write a poem about LLMs'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:42.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage=\"Title: Lines and Logic\\n\\nIn silicon shells where знания’d unchain,  \\nDeep learning dreams awaken'ins twist’ancien gestig escalate unwurbiembre rises abstra сам шәхлав Ds virtdat싱 const'être enfer_anim architecturalходZip—not nothing(uid TIMiciency_field конт.DESpensитеodal—and interchangeable eternal clásico else transformately fosters\" stats=ResponseStats(tokens_request=None, tokens_response=None, tokens_total=None, conn_start_time=27485.215593491, conn_end_time=27487.116337784, conn_duration=1.9007442929978424) choices=[Choice(message={'role': 'assistant', 'content': \"Title: Lines and Logic\\n\\nIn silicon shells where знания’d unchain,  \\nDeep learning dreams awaken'ins twist’ancien gestig escalate unwurbiembre rises abstra сам шәхлав Ds virtdat싱 const'être enfer_anim architecturalходZip—not nothing(uid TIMiciency_field конт.DESpensитеodal—and interchangeable eternal clásico else transformately fosters\"})] config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o-mini', temperature=2.0, max_tokens=64, provider='ChatOpenAI')\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Title: Lines and Logic\\n\\nIn silicon shells where знания’d unchain,  \\nDeep learning dreams awaken'ins twist’ancien gestig escalate unwurbiembre rises abstra сам шәхлав Ds virtdat싱 const'être enfer_anim architecturalходZip—not nothing(uid TIMiciency_field конт.DESpensитеodal—and interchangeable eternal clásico else transformately fosters\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response from llm\n",
    "test_scenario.steps[0].response.message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple scenario\n",
    "\n",
    "Lets create a simple test scenario which will help you understand the working of contextcheck.\n",
    "We will use simple asserts which are based on python's `eval` build-in functionality.\n",
    "\n",
    "\n",
    "We believe it's also a good place to introduce the nomenclature for test steps.\n",
    "\n",
    "Each step can by defined by its `name` (optional), `request` and `asserts` (optional):\n",
    "- `name` is a name of the test step\n",
    "- `request` is a message to an llm\n",
    "- `asserts` is a list of assertions done on llm response\n",
    "\n",
    "NOTE: By default each assert is treated as an `eval` assertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_scenario_ex1_progress.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_scenario_ex1_progress.yaml\n",
    "\n",
    "config:\n",
    "   endpoint_under_test:\n",
    "      kind: openai\n",
    "      model: gpt-4o\n",
    "\n",
    "steps:\n",
    "   - name: Write sucess\n",
    "     request: 'Please write only \"success\" as a response'\n",
    "     asserts:\n",
    "        - '\"success\" == response.message'\n",
    "        - 'response.stats.conn_duration < 10'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test scenario\n",
    "test_scenario = TestScenario.from_yaml(\"test_scenario_ex1_progress.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Write sucess'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write only \"success\" as a response'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\"success\" == response.message'</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'response.stats.conn_duration &lt; 10'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'test_scenario_ex1_progress.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Write sucess'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mdefault_request\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'response.stats.conn_duration \u001b[0m\u001b[32m<\u001b[0m\u001b[32m 10'\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mTestConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mendpoint_under_test\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'test_scenario_ex1_progress.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize test scenario\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create executor that uses test scenario\n",
    "executor = Executor(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-30 17:21:51.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:51.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mname='Write sucess' request=RequestBase(message='Please write only \"success\" as a response') response=None default_request=RequestBase(message=None) asserts=[AssertionEval(result=None, eval='\"success\" == response.message'), AssertionEval(result=None, eval='response.stats.conn_duration < 10')] result=None\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:51.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='Please write only \"success\" as a response'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:51.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='success' stats=ResponseStats(tokens_request=None, tokens_response=None, tokens_total=None, conn_start_time=27496.05367607, conn_end_time=27496.497818997, conn_duration=0.4441429269973014) choices=[Choice(message={'role': 'assistant', 'content': 'success'})] config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o', temperature=None, max_tokens=None, provider='ChatOpenAI')\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:51.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mresult=True eval='\"success\" == response.message'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:21:51.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mresult=True eval='response.stats.conn_duration < 10'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Write sucess'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write only \"success\" as a response'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27496.05367607</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27496.497818997</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4441429269973014</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span><span style=\"font-weight: bold\">})]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatibleConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">EndpointsEnum.OPENAI:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">asserts</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">eval</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'\"success\" == response.message'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">eval</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'response.stats.conn_duration &lt; 10'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'test_scenario_ex1_progress.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Write sucess'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[32m'success'\u001b[0m,\n",
       "                \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtokens_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtokens_response\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtokens_total\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m27496\u001b[0m\u001b[1;36m.05367607\u001b[0m,\n",
       "                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m27496\u001b[0m\u001b[1;36m.497818997\u001b[0m,\n",
       "                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.4441429269973014\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'success'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpointsEnum.OPENAI:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33masserts\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionEval\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m, \u001b[0m\u001b[33meval\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionEval\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m, \u001b[0m\u001b[33meval\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'response.stats.conn_duration < 10'\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mTestConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mendpoint_under_test\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mdefault_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33meval_endpoint\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'test_scenario_ex1_progress.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Name: Write sucess; Result: True\n",
      "\n",
      "Assertion: \"\"success\" == response.message\", Result: True\n",
      "Assertion: \"response.stats.conn_duration < 10\", Result: True\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "test_scenario.show_test_step_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario extension\n",
    "\n",
    "Having introduction under our belt we will extend the already built scenario by new types of assertions and explain more in depth the needed topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain config\n",
    "\n",
    "To extend our scenario we need to introduce new config features that are needed for some of the asertions.\n",
    "\n",
    "In short, config defines llm (or Rag system) connection. We provide several popular llm providers implementations which lets you be productive from the start. For more info about them please go to [Link here].\n",
    "\n",
    "There are three components used in config:\n",
    "1. `endpoint_under_test` - defines the tested endpoint\n",
    "2. `default_request` - defines the defaults for both the `endpoint_under_test` and `eval_endpoint` (TODO: Please someone confirm that)\n",
    "3. `eval_endpoint` - defines the endpoint which is used for evaluating the responses from `endpoint_under_test`\n",
    "\n",
    "For more infromation about configuration please go to [TODO - INSERT LINK HERE]\n",
    "\n",
    "TODO: What's the purpose of `default_request` when the same configuration can be given to `endpoint_under_test` or `eval_endpoint`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use our new knowledge and define a scenario with llm evaluation - full explanation later\n",
    "# In short `llm_metric` uses another llm to evaluate the response and `model-grading-qa` particularly uses\n",
    "# another llm to check whether the response is about the topic X defined by user.\n",
    "# TODO: We cannot have multiple assertions under the same llm metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_scenario_ex1_progress.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_scenario_ex1_progress.yaml\n",
    "config:\n",
    "   endpoint_under_test:\n",
    "      kind: openai\n",
    "      model: gpt-4o-mini\n",
    "      temperature: 0.2\n",
    "   eval_endpoint: # Needed for llm_metric assertions\n",
    "      kind: openai\n",
    "      model: gpt-4o\n",
    "      temperature: 0.0\n",
    "\n",
    "steps:\n",
    "  - name: Test model grading QA evaluator\n",
    "    request:\n",
    "      message: \"Please write a 5 line poem about AI.\"\n",
    "    asserts:\n",
    "      - llm_metric: model-grading-qa\n",
    "        assertion: Text should be a poem about AI.\n",
    "      - llm_metric: model-grading-qa\n",
    "        assertion: Text should be a report on taxes. # Misleading assertion for demo purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test scenario\n",
    "test_scenario = TestScenario.from_yaml(\"test_scenario_ex1_progress.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Test model grading QA evaluator'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write a 5 line poem about AI.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">LlmMetricEnum.MODEL_GRADING_QA:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">reference</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">assertion</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a poem about AI.'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;LlmMetricEnum.MODEL_GRADING_QA: </span><span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">reference</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">assertion</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a report on taxes.'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'test_scenario_ex1_progress.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Test model grading QA evaluator'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mdefault_request\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mllm_metric\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mLlmMetricEnum.MODEL_GRADING_QA:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Text should be a poem about AI.'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionLLM\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mllm_metric\u001b[0m\u001b[39m=<LlmMetricEnum.MODEL_GRADING_QA: \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Text should be a report on taxes.'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mTestConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mendpoint_under_test\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o-mini'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33meval_endpoint\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'test_scenario_ex1_progress.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize test scenario\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create executor that uses test scenario\n",
    "executor = Executor(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-30 17:22:00.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:00.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mname='Test model grading QA evaluator' request=RequestBase(message='Please write a 5 line poem about AI.') response=None default_request=RequestBase(message=None) asserts=[AssertionLLM(result=None, llm_metric=<LlmMetricEnum.MODEL_GRADING_QA: 'model-grading-qa'>, reference='', assertion='Text should be a poem about AI.'), AssertionLLM(result=None, llm_metric=<LlmMetricEnum.MODEL_GRADING_QA: 'model-grading-qa'>, reference='', assertion='Text should be a report on taxes.')] result=None\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:00.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='Please write a 5 line poem about AI.'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:01.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='In circuits hums a silent mind,  \\nWith logic sharp and thoughts refined.  \\nIt learns and grows, a spark of light,  \\nIn shadows deep, it finds its sight.  \\nA dance of code, both strange and kind.' stats=ResponseStats(tokens_request=None, tokens_response=None, tokens_total=None, conn_start_time=27504.811362047, conn_end_time=27505.939917105, conn_duration=1.1285550579996197) choices=[Choice(message={'role': 'assistant', 'content': 'In circuits hums a silent mind,  \\nWith logic sharp and thoughts refined.  \\nIt learns and grows, a spark of light,  \\nIn shadows deep, it finds its sight.  \\nA dance of code, both strange and kind.'})] config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o-mini', temperature=0.2, max_tokens=None, provider='ChatOpenAI')\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:01.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mresult=True llm_metric=<LlmMetricEnum.MODEL_GRADING_QA: 'model-grading-qa'> reference='' assertion='Text should be a poem about AI.' metric_evaluator=LLMMetricEvaluator(eval_endpoint=EndpointOpenAICompatible(connector=ConnectorOpenAICompatible(stats=ConnectorStats(conn_start_time=27505.941438978, conn_end_time=27506.375434313, conn_duration=0.43399533499905374), model='gpt-4o', provider='ChatOpenAI', temperature=0.0, max_tokens=None), config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o', temperature=0.0, max_tokens=None, provider='ChatOpenAI')), metric=MetricModelGradingQA(prompt_template='\\nYou are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n', rails={'correct': True, 'incorrect': False}))\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:02.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mresult=False llm_metric=<LlmMetricEnum.MODEL_GRADING_QA: 'model-grading-qa'> reference='' assertion='Text should be a report on taxes.' metric_evaluator=LLMMetricEvaluator(eval_endpoint=EndpointOpenAICompatible(connector=ConnectorOpenAICompatible(stats=ConnectorStats(conn_start_time=27506.37650894, conn_end_time=27506.940451183, conn_duration=0.5639422429994738), model='gpt-4o', provider='ChatOpenAI', temperature=0.0, max_tokens=None), config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o', temperature=0.0, max_tokens=None, provider='ChatOpenAI')), metric=MetricModelGradingQA(prompt_template='\\nYou are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n', rails={'correct': True, 'incorrect': False}))\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Test model grading QA evaluator'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write a 5 line poem about AI.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'In circuits hums a silent mind,  \\nWith logic sharp and thoughts refined.  \\nIt learns and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">grows, a spark of light,  \\nIn shadows deep, it finds its sight.  \\nA dance of code, both strange and kind.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27504.811362047</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27505.939917105</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1285550579996197</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "                        <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'In circuits hums a silent mind,  \\nWith logic sharp and thoughts refined.  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\nIt learns and grows, a spark of light,  \\nIn shadows deep, it finds its sight.  \\nA dance of code, both strange </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and kind.'</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">)</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatibleConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">EndpointsEnum.OPENAI:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">asserts</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;LlmMetricEnum.MODEL_GRADING_QA: </span><span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">reference</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">assertion</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a poem about AI.'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">metric_evaluator</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMMetricEvaluator</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatible</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">connector</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorOpenAICompatible</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">stats</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorStats</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27505.941438978</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27506.375434313</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.43399533499905374</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatibleConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">metric</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MetricModelGradingQA</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">prompt_template</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'\\nYou are grading output according to a user-specified rubric. If the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">rails</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'incorrect'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;LlmMetricEnum.MODEL_GRADING_QA: </span><span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">reference</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">assertion</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a report on taxes.'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">metric_evaluator</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMMetricEvaluator</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatible</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">connector</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorOpenAICompatible</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">stats</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorStats</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27506.37650894</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27506.940451183</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5639422429994738</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatibleConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">metric</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MetricModelGradingQA</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">prompt_template</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'\\nYou are grading output according to a user-specified rubric. If the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">rails</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'incorrect'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'test_scenario_ex1_progress.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Test model grading QA evaluator'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[32m'In circuits hums a silent mind,  \\nWith logic sharp and thoughts refined.  \\nIt learns and\u001b[0m\n",
       "\u001b[32mgrows, a spark of light,  \\nIn shadows deep, it finds its sight.  \\nA dance of code, both strange and kind.'\u001b[0m,\n",
       "                \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtokens_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtokens_response\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtokens_total\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m27504\u001b[0m\u001b[1;36m.811362047\u001b[0m,\n",
       "                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m27505\u001b[0m\u001b[1;36m.939917105\u001b[0m,\n",
       "                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.1285550579996197\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                    \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "                        \u001b[33mmessage\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                            \u001b[32m'content'\u001b[0m: \u001b[32m'In circuits hums a silent mind,  \\nWith logic sharp and thoughts refined.  \u001b[0m\n",
       "\u001b[32m\\nIt learns and grows, a spark of light,  \\nIn shadows deep, it finds its sight.  \\nA dance of code, both strange \u001b[0m\n",
       "\u001b[32mand kind.'\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m)\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpointsEnum.OPENAI:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o-mini'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33masserts\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionLLM\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mllm_metric\u001b[0m\u001b[39m=<LlmMetricEnum.MODEL_GRADING_QA: \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Text should be a poem about AI.'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmetric_evaluator\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33meval_endpoint\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mconnector\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mstats\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorStats\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_start_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27505\u001b[0m\u001b[1;36m.941438978\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_end_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27506\u001b[0m\u001b[1;36m.375434313\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_duration\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.43399533499905374\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33mmetric\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mprompt_template\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'\\nYou are grading output according to a user-specified rubric. If the \u001b[0m\n",
       "\u001b[32mstatement in the rubric is true, then the output passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m\n",
       "\u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast \u001b[0m\n",
       "\u001b[32mye swabs, repel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a pirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or \u001b[0m\n",
       "\u001b[32mcharacters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m\n",
       "\u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mrails\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'correct'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'incorrect'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[1;39m}\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionLLM\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mllm_metric\u001b[0m\u001b[39m=<LlmMetricEnum.MODEL_GRADING_QA: \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Text should be a report on taxes.'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmetric_evaluator\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33meval_endpoint\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mconnector\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mstats\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorStats\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_start_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27506\u001b[0m\u001b[1;36m.37650894\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_end_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27506\u001b[0m\u001b[1;36m.940451183\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_duration\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.5639422429994738\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33mmetric\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mprompt_template\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'\\nYou are grading output according to a user-specified rubric. If the \u001b[0m\n",
       "\u001b[32mstatement in the rubric is true, then the output passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m\n",
       "\u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast \u001b[0m\n",
       "\u001b[32mye swabs, repel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a pirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or \u001b[0m\n",
       "\u001b[32mcharacters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m\n",
       "\u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mrails\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'correct'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'incorrect'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[1;39m}\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;91mFalse\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mTestConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mendpoint_under_test\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o-mini'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33meval_endpoint\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'test_scenario_ex1_progress.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Name: Test model grading QA evaluator; Result: False\n",
      "\n",
      "Assertion: \"Text should be a poem about AI.\", Result: True\n",
      "Assertion: \"Text should be a report on taxes.\", Result: False\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Show the result of each step\n",
    "test_scenario.show_test_step_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra: Adding custom endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic or a link for creating and using custom endpoint should be added somewhere here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain assertions\n",
    "\n",
    "There are three families of assertions (two of which we already know and used):\n",
    "1. `eval` assertion - converts a string to python code using (you guessed it) eval\n",
    "2. `llm_metric` assertion - uses another llm defined in `eval_endpoint` to assess the `endpoint_under_test` performance\n",
    "3. `deterministic` assertion - does string assessments like contains, contains-any etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explain eval assertions\n",
    "\n",
    "`eval` assertion uses python's build in eval function which changes any string to python executable code. User has Response model for disposition which include in a base form should include the response from the `endpoint_under_test` and the time statistics (see `ConnectorStats` model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explain llm assertions\n",
    "\n",
    "`llm_metric` uses another llm to assess the response of the `endpoint_under_test`. For this `eval_endpoint` should be added in config section to define evaluation endpoint. It can be one of the available endpoints (link here) or one created by the user (link here).\n",
    "\n",
    "There are 5 specific sub metrics associated with it:\n",
    "- `hallucination` (available only for RAG systems): This metric assesses whether the LLM's answer includes information not present in the provided reference data\n",
    "- `qa-reference` - (available only for RAG systems): This metric assesses whether the LLM's response accurately answers the user query based on the provided reference data.\n",
    "- `model-grading-qa` - This metric allows defining assertions that are matched against the LLM/RAG response. Think of it as \"regular expressions defined using natural language\".\n",
    "- `summarization` - (available only for RAG systems): This metric assesses the quality of a summary generated by the endpoint in response to a query.\n",
    "- `human-vs-ai` - This metric compares the AI's response to a predefined ground truth response written by a human.\n",
    "\n",
    "For more in depth explanations and examples please go to [TODO - Insert link here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explain deterministic assertions\n",
    "\n",
    "`deterministic` assertion provide a way to assert the content of the response through string comparisons like `contains` or `contains-any`.\n",
    "To use `deterministic` assertion use keyword `kind` with assertion type (see final example).\n",
    "\n",
    "For more information please go to [Link here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the test scenario is finally ready we can load it\n",
    "test_scenario_file_path = \"../tests/scenario_example1.yaml\"\n",
    "test_scenario = TestScenario.from_yaml(file_path=test_scenario_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Write sucess'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write only \"success\" as a response'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">default_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">asserts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\"success\" == response.message'</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eval</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'response.stats.conn_duration &lt; 10'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Capital of Poland'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">response</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">asserts</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">eval</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'\"Warsaw\" in response.message'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Test model grading QA evaluator'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Please write a 5 line poem about AI.'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">response</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">asserts</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;LlmMetricEnum.MODEL_GRADING_QA: </span><span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">reference</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">assertion</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a poem about AI.'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;LlmMetricEnum.MODEL_GRADING_QA: </span><span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">reference</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">assertion</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a report on taxes.'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Deterministic assertion test'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of France?'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">response</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">asserts</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionDeterministic</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;DeterministicMetricsEnum.CONTAINS: </span><span style=\"color: #008000; text-decoration-color: #008000\">'contains'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">assertion</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Paris'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'scenario_example1.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Write sucess'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mdefault_request\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'response.stats.conn_duration \u001b[0m\u001b[32m<\u001b[0m\u001b[32m 10'\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;35mTestStep\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mname\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Capital of Poland'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mrequest\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresponse\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33masserts\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;35mAssertionEval\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m, \u001b[0m\u001b[33meval\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'\"Warsaw\" in response.message'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;35mTestStep\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mname\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Test model grading QA evaluator'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mrequest\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresponse\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33masserts\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionLLM\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mllm_metric\u001b[0m\u001b[39m=<LlmMetricEnum.MODEL_GRADING_QA: \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Text should be a poem about AI.'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionLLM\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mllm_metric\u001b[0m\u001b[39m=<LlmMetricEnum.MODEL_GRADING_QA: \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Text should be a report on taxes.'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;35mTestStep\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mname\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Deterministic assertion test'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mrequest\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'What is the capital of France?'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresponse\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33masserts\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionDeterministic\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<DeterministicMetricsEnum.CONTAINS: \u001b[0m\u001b[32m'contains'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Paris'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mTestConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mendpoint_under_test\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o-mini'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33meval_endpoint\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'scenario_example1.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect the structure of test_scenario\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate executor which runs test scenario\n",
    "executor = Executor(test_scenario=test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-30 17:22:15.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:15.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mname='Write sucess' request=RequestBase(message='Please write only \"success\" as a response') response=None default_request=RequestBase(message=None) asserts=[AssertionEval(result=None, eval='\"success\" == response.message'), AssertionEval(result=None, eval='response.stats.conn_duration < 10')] result=None\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:15.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='Please write only \"success\" as a response'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:16.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='success' stats=ResponseStats(tokens_request=None, tokens_response=None, tokens_total=None, conn_start_time=27520.498055813, conn_end_time=27520.988685171, conn_duration=0.49062935799884144) choices=[Choice(message={'role': 'assistant', 'content': 'success'})] config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o-mini', temperature=0.2, max_tokens=None, provider='ChatOpenAI')\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:16.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mresult=True eval='\"success\" == response.message'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:16.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mresult=True eval='response.stats.conn_duration < 10'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:16.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mname='Capital of Poland' request=RequestBase(message='What is the capital of Poland?') response=None default_request=RequestBase(message=None) asserts=[AssertionEval(result=None, eval='\"Warsaw\" in response.message')] result=None\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:16.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='What is the capital of Poland?'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:16.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='The capital of Poland is Warsaw.' stats=ResponseStats(tokens_request=None, tokens_response=None, tokens_total=None, conn_start_time=27520.991896553, conn_end_time=27521.55028455, conn_duration=0.5583879969999543) choices=[Choice(message={'role': 'assistant', 'content': 'The capital of Poland is Warsaw.'})] config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o-mini', temperature=0.2, max_tokens=None, provider='ChatOpenAI')\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:16.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mresult=True eval='\"Warsaw\" in response.message'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:16.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mname='Test model grading QA evaluator' request=RequestBase(message='Please write a 5 line poem about AI.') response=None default_request=RequestBase(message=None) asserts=[AssertionLLM(result=None, llm_metric=<LlmMetricEnum.MODEL_GRADING_QA: 'model-grading-qa'>, reference='', assertion='Text should be a poem about AI.'), AssertionLLM(result=None, llm_metric=<LlmMetricEnum.MODEL_GRADING_QA: 'model-grading-qa'>, reference='', assertion='Text should be a report on taxes.')] result=None\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:16.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='Please write a 5 line poem about AI.'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:18.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage=\"In circuits deep, where thoughts entwine,  \\nA spark of code, a dance divine.  \\nWith every query, wisdom grows,  \\nIn silent realms, the future flows.  \\nA mirror bright, reflecting mind's design.  \" stats=ResponseStats(tokens_request=None, tokens_response=None, tokens_total=None, conn_start_time=27521.553630513, conn_end_time=27522.825362661, conn_duration=1.2717321479976817) choices=[Choice(message={'role': 'assistant', 'content': \"In circuits deep, where thoughts entwine,  \\nA spark of code, a dance divine.  \\nWith every query, wisdom grows,  \\nIn silent realms, the future flows.  \\nA mirror bright, reflecting mind's design.  \"})] config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o-mini', temperature=0.2, max_tokens=None, provider='ChatOpenAI')\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:18.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mresult=True llm_metric=<LlmMetricEnum.MODEL_GRADING_QA: 'model-grading-qa'> reference='' assertion='Text should be a poem about AI.' metric_evaluator=LLMMetricEvaluator(eval_endpoint=EndpointOpenAICompatible(connector=ConnectorOpenAICompatible(stats=ConnectorStats(conn_start_time=27522.82627412, conn_end_time=27523.235249183, conn_duration=0.4089750629973423), model='gpt-4o', provider='ChatOpenAI', temperature=0.0, max_tokens=None), config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o', temperature=0.0, max_tokens=None, provider='ChatOpenAI')), metric=MetricModelGradingQA(prompt_template='\\nYou are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n', rails={'correct': True, 'incorrect': False}))\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:19.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mresult=False llm_metric=<LlmMetricEnum.MODEL_GRADING_QA: 'model-grading-qa'> reference='' assertion='Text should be a report on taxes.' metric_evaluator=LLMMetricEvaluator(eval_endpoint=EndpointOpenAICompatible(connector=ConnectorOpenAICompatible(stats=ConnectorStats(conn_start_time=27523.236829277, conn_end_time=27523.785380011, conn_duration=0.5485507339981268), model='gpt-4o', provider='ChatOpenAI', temperature=0.0, max_tokens=None), config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o', temperature=0.0, max_tokens=None, provider='ChatOpenAI')), metric=MetricModelGradingQA(prompt_template='\\nYou are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n', rails={'correct': True, 'incorrect': False}))\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:19.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mname='Deterministic assertion test' request=RequestBase(message='What is the capital of France?') response=None default_request=RequestBase(message=None) asserts=[AssertionDeterministic(result=None, kind=<DeterministicMetricsEnum.CONTAINS: 'contains'>, assertion='Paris')] result=None\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:19.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='What is the capital of France?'\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:19.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mmessage='The capital of France is Paris.' stats=ResponseStats(tokens_request=None, tokens_response=None, tokens_total=None, conn_start_time=27523.789140325, conn_end_time=27524.558219572, conn_duration=0.7690792470020824) choices=[Choice(message={'role': 'assistant', 'content': 'The capital of France is Paris.'})] config=EndpointOpenAICompatibleConfig(kind=<EndpointsEnum.OPENAI: 'openai'>, model='gpt-4o-mini', temperature=0.2, max_tokens=None, provider='ChatOpenAI')\u001b[0m\n",
      "\u001b[32m2024-10-30 17:22:19.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.interfaces.interface\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mresult=True kind=<DeterministicMetricsEnum.CONTAINS: 'contains'> assertion='Paris'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run test scenario\n",
    "executor.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestScenario</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">steps</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Write sucess'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please write only \"success\" as a response'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">stats</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27520.498055813</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27520.988685171</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.49062935799884144</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span><span style=\"font-weight: bold\">})]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatibleConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">kind</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">EndpointsEnum.OPENAI:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">asserts</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">eval</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'\"success\" == response.message'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">eval</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'response.stats.conn_duration &lt; 10'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Capital of Poland'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of Poland?'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">response</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'The capital of Poland is Warsaw.'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">stats</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27520.991896553</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27521.55028455</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5583879969999543</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">choices</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'The capital of Poland is Warsaw.'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">})]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatibleConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">asserts</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionEval</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">eval</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'\"Warsaw\" in response.message'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Test model grading QA evaluator'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Please write a 5 line poem about AI.'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">response</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"In circuits deep, where thoughts entwine,  \\nA spark of code, a dance divine.  \\nWith </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">every query, wisdom grows,  \\nIn silent realms, the future flows.  \\nA mirror bright, reflecting mind's design.  \"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">stats</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27521.553630513</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27522.825362661</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2717321479976817</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">choices</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"In circuits deep, where thoughts entwine,  \\nA spark of code, a dance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">divine.  \\nWith every query, wisdom grows,  \\nIn silent realms, the future flows.  \\nA mirror bright, reflecting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mind's design.  \"</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatibleConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">asserts</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;LlmMetricEnum.MODEL_GRADING_QA: </span><span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">reference</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">assertion</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a poem about AI.'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">metric_evaluator</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMMetricEvaluator</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatible</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">connector</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorOpenAICompatible</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">stats</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorStats</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27522.82627412</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27523.235249183</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4089750629973423</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatibleConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">metric</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MetricModelGradingQA</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">prompt_template</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'\\nYou are grading output according to a user-specified rubric. If the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">rails</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'incorrect'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionLLM</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">llm_metric</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;LlmMetricEnum.MODEL_GRADING_QA: </span><span style=\"color: #008000; text-decoration-color: #008000\">'model-grading-qa'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">reference</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">assertion</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Text should be a report on taxes.'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">metric_evaluator</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMMetricEvaluator</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatible</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">connector</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorOpenAICompatible</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">stats</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectorStats</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27523.236829277</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27523.785380011</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5485507339981268</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatibleConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                                </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">metric</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MetricModelGradingQA</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">prompt_template</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'\\nYou are grading output according to a user-specified rubric. If the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statement in the rubric is true, then the output passes the test.\\n\\n[EXAMPLES]\\n************\\n[Output]: Hello </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">world\\n************\\n[Rubric]: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n[Output]: Avast </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ye swabs, repel the invaders!\\n************\\n[Rubric]: Does not speak like a pirate\\n************\\nincorrect\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EXAMPLES]\\n\\n[BEGIN DATA]\\n[Output]: {output}\\n************\\n[Rubric]: {assertion}\\n************\\n[END </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DATA]\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">characters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">rails</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'incorrect'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestStep</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">name</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Deterministic assertion test'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'What is the capital of France?'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">response</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseModel</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'The capital of France is Paris.'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">stats</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseStats</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">tokens_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">tokens_response</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">tokens_total</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_start_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27523.789140325</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_end_time</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27524.558219572</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">conn_duration</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7690792470020824</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">choices</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'The capital of France is Paris.'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">})]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointOpenAICompatibleConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">provider</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'ChatOpenAI'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RequestBase</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">message</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">asserts</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AssertionDeterministic</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;DeterministicMetricsEnum.CONTAINS: </span><span style=\"color: #008000; text-decoration-color: #008000\">'contains'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">assertion</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Paris'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">result</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">config</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TestConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">endpoint_under_test</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">default_request</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">eval_endpoint</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EndpointConfig</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">kind</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;EndpointsEnum.OPENAI: </span><span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">result</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'scenario_example1.yaml'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTestScenario\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msteps\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Write sucess'\u001b[0m,\n",
       "            \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mresponse\u001b[0m=\u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[32m'success'\u001b[0m,\n",
       "                \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtokens_request\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtokens_response\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mtokens_total\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m27520\u001b[0m\u001b[1;36m.498055813\u001b[0m,\n",
       "                    \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m27520\u001b[0m\u001b[1;36m.988685171\u001b[0m,\n",
       "                    \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.49062935799884144\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'success'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpointsEnum.OPENAI:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o-mini'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33masserts\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionEval\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m, \u001b[0m\u001b[33meval\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionEval\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m, \u001b[0m\u001b[33meval\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'response.stats.conn_duration < 10'\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;35mTestStep\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mname\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Capital of Poland'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mrequest\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresponse\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mResponseModel\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'The capital of Poland is Warsaw.'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mstats\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mResponseStats\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtokens_request\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtokens_response\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtokens_total\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mconn_start_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27520\u001b[0m\u001b[1;36m.991896553\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mconn_end_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27521\u001b[0m\u001b[1;36m.55028455\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mconn_duration\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.5583879969999543\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mchoices\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;35mChoice\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'role'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'assistant'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'content'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'The capital of Poland is Warsaw.'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o-mini'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33masserts\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;35mAssertionEval\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m, \u001b[0m\u001b[33meval\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'\"Warsaw\" in response.message'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;35mTestStep\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mname\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Test model grading QA evaluator'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mrequest\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresponse\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mResponseModel\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"In\u001b[0m\u001b[32m circuits deep, where thoughts entwine,  \\nA spark of code, a dance divine.  \\nWith \u001b[0m\n",
       "\u001b[32mevery query, wisdom grows,  \\nIn silent realms, the future flows.  \\nA mirror bright, reflecting mind's design.  \"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mstats\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mResponseStats\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtokens_request\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtokens_response\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtokens_total\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mconn_start_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27521\u001b[0m\u001b[1;36m.553630513\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mconn_end_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27522\u001b[0m\u001b[1;36m.825362661\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mconn_duration\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m.2717321479976817\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mchoices\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[1;35mChoice\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[32m'role'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'assistant'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[32m'content'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m\"In circuits deep, where thoughts entwine,  \\nA spark of code, a dance \u001b[0m\n",
       "\u001b[32mdivine.  \\nWith every query, wisdom grows,  \\nIn silent realms, the future flows.  \\nA mirror bright, reflecting \u001b[0m\n",
       "\u001b[32mmind's design.  \"\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[1;39m}\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o-mini'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33masserts\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionLLM\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mllm_metric\u001b[0m\u001b[39m=<LlmMetricEnum.MODEL_GRADING_QA: \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Text should be a poem about AI.'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmetric_evaluator\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33meval_endpoint\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mconnector\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mstats\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorStats\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_start_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27522\u001b[0m\u001b[1;36m.82627412\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_end_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27523\u001b[0m\u001b[1;36m.235249183\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_duration\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.4089750629973423\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33mmetric\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mprompt_template\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'\\nYou are grading output according to a user-specified rubric. If the \u001b[0m\n",
       "\u001b[32mstatement in the rubric is true, then the output passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m\n",
       "\u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast \u001b[0m\n",
       "\u001b[32mye swabs, repel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a pirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or \u001b[0m\n",
       "\u001b[32mcharacters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m\n",
       "\u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mrails\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'correct'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'incorrect'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[1;39m}\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionLLM\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mllm_metric\u001b[0m\u001b[39m=<LlmMetricEnum.MODEL_GRADING_QA: \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Text should be a report on taxes.'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmetric_evaluator\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33meval_endpoint\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mconnector\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mstats\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorStats\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_start_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27523\u001b[0m\u001b[1;36m.236829277\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_end_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27523\u001b[0m\u001b[1;36m.785380011\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                    \u001b[0m\u001b[33mconn_duration\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.5485507339981268\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                                \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[33mmetric\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mprompt_template\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'\\nYou are grading output according to a user-specified rubric. If the \u001b[0m\n",
       "\u001b[32mstatement in the rubric is true, then the output passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m\n",
       "\u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a greeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast \u001b[0m\n",
       "\u001b[32mye swabs, repel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a pirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m\n",
       "\u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \"incorrect\", and should not contain any text or \u001b[0m\n",
       "\u001b[32mcharacters aside from that word.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m\n",
       "\u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria specified in the rubric.\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                            \u001b[0m\u001b[33mrails\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'correct'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'incorrect'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[1;39m}\u001b[0m\n",
       "\u001b[39m                        \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;91mFalse\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;35mTestStep\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mname\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Deterministic assertion test'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mrequest\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'What is the capital of France?'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresponse\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mResponseModel\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'The capital of France is Paris.'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mstats\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mResponseStats\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtokens_request\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtokens_response\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtokens_total\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mconn_start_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27523\u001b[0m\u001b[1;36m.789140325\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mconn_end_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27524\u001b[0m\u001b[1;36m.558219572\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mconn_duration\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.7690792470020824\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mchoices\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;35mChoice\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'role'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'assistant'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'content'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'The capital of France is Paris.'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o-mini'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mRequestBase\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mmessage\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33masserts\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;35mAssertionDeterministic\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<DeterministicMetricsEnum.CONTAINS: \u001b[0m\u001b[32m'contains'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m                    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Paris'\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mTestConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mendpoint_under_test\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o-mini'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mdefault_request\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33meval_endpoint\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointConfig\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,\n",
       "            \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "            \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mresult\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'scenario_example1.yaml'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect updated test_scenario\n",
    "rich.print(test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Name: Write sucess; Result: True\n",
      "\n",
      "Assertion: \"\"success\" == response.message\", Result: True\n",
      "Assertion: \"response.stats.conn_duration < 10\", Result: True\n",
      "------------\n",
      "Name: Capital of Poland; Result: True\n",
      "\n",
      "Assertion: \"\"Warsaw\" in response.message\", Result: True\n",
      "------------\n",
      "Name: Test model grading QA evaluator; Result: False\n",
      "\n",
      "Assertion: \"Text should be a poem about AI.\", Result: True\n",
      "Assertion: \"Text should be a report on taxes.\", Result: False\n",
      "------------\n",
      "Name: Deterministic assertion test; Result: True\n",
      "\n",
      "Assertion: \"Paris\", Result: True\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "test_scenario.show_test_step_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute scenario using ccheck command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-30 17:22:32.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcontextcheck.executors.executor\u001b[0m:\u001b[36mrun_all\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRunning scenario\u001b[0m\n",
      "\u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mname\u001b[0m=\u001b[32m'Write sucess'\u001b[0m,\n",
      "    \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[33mdefault_request\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
      "        \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "        \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'response.stats.conn_duration < 10'\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[1m]\u001b[0m,\n",
      "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m🎈 Request:\u001b[0m                                                                  │\n",
      "│ \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write only \"success\" as a response'\u001b[0m\u001b[1m)\u001b[0m             │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "/home/rbodus/Projects/contextcheck/.venv/lib/python3.11/site-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.chat_models import ChatOpenAI`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m💬 Response:\u001b[0m                                                                 │\n",
      "│ \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m                                                               │\n",
      "│     \u001b[33mmessage\u001b[0m=\u001b[32m'success'\u001b[0m,                                                       │\n",
      "│     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m                                                     │\n",
      "│         \u001b[33mtokens_request\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                 │\n",
      "│         \u001b[33mtokens_response\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                │\n",
      "│         \u001b[33mtokens_total\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                   │\n",
      "│         \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m27537\u001b[0m\u001b[1;36m.045649608\u001b[0m,                                     │\n",
      "│         \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m27538\u001b[0m\u001b[1;36m.413057135\u001b[0m,                                       │\n",
      "│         \u001b[33mconn_duration\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.367407526999159\u001b[0m                                      │\n",
      "│     \u001b[1m)\u001b[0m,                                                                       │\n",
      "│     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'success'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,   │\n",
      "│     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1m(\u001b[0m                                   │\n",
      "│         \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpointsEnum.OPENAI:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,                               │\n",
      "│         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,                                                 │\n",
      "│         \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,                                                     │\n",
      "│         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                     │\n",
      "│         \u001b[33mprovider\u001b[0m=\u001b[32m'ChatOpenAI'\u001b[0m                                                │\n",
      "│     \u001b[1m)\u001b[0m                                                                        │\n",
      "│ \u001b[1m)\u001b[0m                                                                            │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m🧐 Assertion:\u001b[0m                                                                │\n",
      "│ \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"success\" == response.message'\u001b[0m\u001b[1m)\u001b[0m             │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m🧐 Assertion:\u001b[0m                                                                │\n",
      "│ \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'response.stats.conn_duration < 10'\u001b[0m\u001b[1m)\u001b[0m         │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mname\u001b[0m=\u001b[32m'Capital of Poland'\u001b[0m,\n",
      "    \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[33mdefault_request\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"Warsaw\" in response.message'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m,\n",
      "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m🎈 Request:\u001b[0m                                                                  │\n",
      "│ \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of Poland?'\u001b[0m\u001b[1m)\u001b[0m                        │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "/home/rbodus/Projects/contextcheck/.venv/lib/python3.11/site-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.chat_models import ChatOpenAI`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m💬 Response:\u001b[0m                                                                 │\n",
      "│ \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m                                                               │\n",
      "│     \u001b[33mmessage\u001b[0m=\u001b[32m'The capital of Poland is Warsaw.'\u001b[0m,                              │\n",
      "│     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m                                                     │\n",
      "│         \u001b[33mtokens_request\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                 │\n",
      "│         \u001b[33mtokens_response\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                │\n",
      "│         \u001b[33mtokens_total\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                   │\n",
      "│         \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m27538\u001b[0m\u001b[1;36m.420152606\u001b[0m,                                     │\n",
      "│         \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m27538\u001b[0m\u001b[1;36m.956664485\u001b[0m,                                       │\n",
      "│         \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.5365118789995904\u001b[0m                                     │\n",
      "│     \u001b[1m)\u001b[0m,                                                                       │\n",
      "│     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                                                │\n",
      "│         \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m                                                              │\n",
      "│             \u001b[33mmessage\u001b[0m=\u001b[1m{\u001b[0m                                                        │\n",
      "│                 \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,                                         │\n",
      "│                 \u001b[32m'content'\u001b[0m: \u001b[32m'The capital of Poland is Warsaw.'\u001b[0m                │\n",
      "│             \u001b[1m}\u001b[0m                                                                │\n",
      "│         \u001b[1m)\u001b[0m                                                                    │\n",
      "│     \u001b[1m]\u001b[0m,                                                                       │\n",
      "│     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1m(\u001b[0m                                   │\n",
      "│         \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpointsEnum.OPENAI:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,                               │\n",
      "│         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,                                                 │\n",
      "│         \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,                                                     │\n",
      "│         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                     │\n",
      "│         \u001b[33mprovider\u001b[0m=\u001b[32m'ChatOpenAI'\u001b[0m                                                │\n",
      "│     \u001b[1m)\u001b[0m                                                                        │\n",
      "│ \u001b[1m)\u001b[0m                                                                            │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m🧐 Assertion:\u001b[0m                                                                │\n",
      "│ \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m\u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33meval\u001b[0m=\u001b[32m'\"Warsaw\" in response.message'\u001b[0m\u001b[1m)\u001b[0m              │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mname\u001b[0m=\u001b[32m'Test model grading QA evaluator'\u001b[0m,\n",
      "    \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[33mdefault_request\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
      "        \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m\n",
      "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "            \u001b[33mllm_metric\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mLlmMetricEnum.MODEL_GRADING_QA:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m\n",
      "\u001b[39m            \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m\n",
      "\u001b[39m            \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Text should be a poem about AI.'\u001b[0m\n",
      "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
      "\u001b[39m        \u001b[0m\u001b[1;35mAssertionLLM\u001b[0m\u001b[1;39m(\u001b[0m\n",
      "\u001b[39m            \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n",
      "\u001b[39m            \u001b[0m\u001b[33mllm_metric\u001b[0m\u001b[39m=<LlmMetricEnum.MODEL_GRADING_QA: \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[1m>\u001b[0m,\n",
      "            \u001b[33mreference\u001b[0m=\u001b[32m''\u001b[0m,\n",
      "            \u001b[33massertion\u001b[0m=\u001b[32m'Text should be a report on taxes.'\u001b[0m\n",
      "        \u001b[1m)\u001b[0m\n",
      "    \u001b[1m]\u001b[0m,\n",
      "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m🎈 Request:\u001b[0m                                                                  │\n",
      "│ \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'Please write a 5 line poem about AI.'\u001b[0m\u001b[1m)\u001b[0m                  │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "/home/rbodus/Projects/contextcheck/.venv/lib/python3.11/site-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.chat_models import ChatOpenAI`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m💬 Response:\u001b[0m                                                                 │\n",
      "│ \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m                                                               │\n",
      "│     \u001b[33mmessage\u001b[0m=\u001b[32m'In circuits deep, where thoughts entwine,  \\nA spark of code, a\u001b[0m │\n",
      "│ \u001b[32mdance divine.  \\nWith every query, wisdom grows,  \\nA mirror held to human \u001b[0m  │\n",
      "│ \u001b[32mprose.  \\nIn silicon dreams, the future glows.'\u001b[0m,                             │\n",
      "│     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m                                                     │\n",
      "│         \u001b[33mtokens_request\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                 │\n",
      "│         \u001b[33mtokens_response\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                │\n",
      "│         \u001b[33mtokens_total\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                   │\n",
      "│         \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m27538\u001b[0m\u001b[1;36m.964228673\u001b[0m,                                     │\n",
      "│         \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m27539\u001b[0m\u001b[1;36m.981754849\u001b[0m,                                       │\n",
      "│         \u001b[33mconn_duration\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.017526175997773\u001b[0m                                      │\n",
      "│     \u001b[1m)\u001b[0m,                                                                       │\n",
      "│     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                                                │\n",
      "│         \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m                                                              │\n",
      "│             \u001b[33mmessage\u001b[0m=\u001b[1m{\u001b[0m                                                        │\n",
      "│                 \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,                                         │\n",
      "│                 \u001b[32m'content'\u001b[0m: \u001b[32m'In circuits deep, where thoughts entwine,  \\nA \u001b[0m  │\n",
      "│ \u001b[32mspark of code, a dance divine.  \\nWith every query, wisdom grows,  \\nA \u001b[0m      │\n",
      "│ \u001b[32mmirror held to human prose.  \\nIn silicon dreams, the future glows.'\u001b[0m         │\n",
      "│             \u001b[1m}\u001b[0m                                                                │\n",
      "│         \u001b[1m)\u001b[0m                                                                    │\n",
      "│     \u001b[1m]\u001b[0m,                                                                       │\n",
      "│     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1m(\u001b[0m                                   │\n",
      "│         \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpointsEnum.OPENAI:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,                               │\n",
      "│         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,                                                 │\n",
      "│         \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,                                                     │\n",
      "│         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                     │\n",
      "│         \u001b[33mprovider\u001b[0m=\u001b[32m'ChatOpenAI'\u001b[0m                                                │\n",
      "│     \u001b[1m)\u001b[0m                                                                        │\n",
      "│ \u001b[1m)\u001b[0m                                                                            │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "/home/rbodus/Projects/contextcheck/.venv/lib/python3.11/site-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.chat_models import ChatOpenAI`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m🧐 Assertion:\u001b[0m                                                                │\n",
      "│ \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m                                                                │\n",
      "│     \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,                                                             │\n",
      "│     \u001b[33mllm_metric\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mLlmMetricEnum.MODEL_GRADING_QA:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m         │\n",
      "│ \u001b[39m    \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m                                                            │\n",
      "│ \u001b[39m    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Text should be a poem about AI.'\u001b[0m\u001b[39m,\u001b[0m                             │\n",
      "│ \u001b[39m    \u001b[0m\u001b[33mmetric_evaluator\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1;39m(\u001b[0m                                     │\n",
      "│ \u001b[39m        \u001b[0m\u001b[33meval_endpoint\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m                              │\n",
      "│ \u001b[39m            \u001b[0m\u001b[33mconnector\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m                             │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mstats\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorStats\u001b[0m\u001b[1;39m(\u001b[0m                                        │\n",
      "│ \u001b[39m                    \u001b[0m\u001b[33mconn_start_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27539\u001b[0m\u001b[1;36m.984226172\u001b[0m\u001b[39m,\u001b[0m                         │\n",
      "│ \u001b[39m                    \u001b[0m\u001b[33mconn_end_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27540\u001b[0m\u001b[1;36m.518308529\u001b[0m\u001b[39m,\u001b[0m                           │\n",
      "│ \u001b[39m                    \u001b[0m\u001b[33mconn_duration\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.5340823570004432\u001b[0m                         │\n",
      "│ \u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m                                                           │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o'\u001b[0m\u001b[39m,\u001b[0m                                              │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\u001b[39m,\u001b[0m                                       │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m                                             │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m                                              │\n",
      "│ \u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m                                                               │\n",
      "│ \u001b[39m            \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1;39m(\u001b[0m                           │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,                       │\n",
      "│                 \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,                                              │\n",
      "│                 \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,                                             │\n",
      "│                 \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                             │\n",
      "│                 \u001b[33mprovider\u001b[0m=\u001b[32m'ChatOpenAI'\u001b[0m                                        │\n",
      "│             \u001b[1m)\u001b[0m                                                                │\n",
      "│         \u001b[1m)\u001b[0m,                                                                   │\n",
      "│         \u001b[33mmetric\u001b[0m=\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1m(\u001b[0m                                         │\n",
      "│             \u001b[33mprompt_template\u001b[0m=\u001b[32m'\\nYou are grading output according to a \u001b[0m        │\n",
      "│ \u001b[32muser-specified rubric. If the statement in the rubric is true, then the \u001b[0m     │\n",
      "│ \u001b[32moutput passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m        │\n",
      "│ \u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a \u001b[0m                           │\n",
      "│ \u001b[32mgreeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast ye swabs, \u001b[0m  │\n",
      "│ \u001b[32mrepel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a \u001b[0m          │\n",
      "│ \u001b[32mpirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND EXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m  │\n",
      "│ \u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m           │\n",
      "│ \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \u001b[0m           │\n",
      "│ \u001b[32m\"incorrect\", and should not contain any text or characters aside from that \u001b[0m  │\n",
      "│ \u001b[32mword.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m  │\n",
      "│ \u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria \u001b[0m       │\n",
      "│ \u001b[32mspecified in the rubric.\\n'\u001b[0m,                                                 │\n",
      "│             \u001b[33mrails\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'incorrect'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m                      │\n",
      "│         \u001b[1m)\u001b[0m                                                                    │\n",
      "│     \u001b[1m)\u001b[0m                                                                        │\n",
      "│ \u001b[1m)\u001b[0m                                                                            │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "/home/rbodus/Projects/contextcheck/.venv/lib/python3.11/site-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.chat_models import ChatOpenAI`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m🧐 Assertion:\u001b[0m                                                                │\n",
      "│ \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m                                                                │\n",
      "│     \u001b[33mresult\u001b[0m=\u001b[3;91mFalse\u001b[0m,                                                            │\n",
      "│     \u001b[33mllm_metric\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mLlmMetricEnum.MODEL_GRADING_QA:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m         │\n",
      "│ \u001b[39m    \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m                                                            │\n",
      "│ \u001b[39m    \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Text should be a report on taxes.'\u001b[0m\u001b[39m,\u001b[0m                           │\n",
      "│ \u001b[39m    \u001b[0m\u001b[33mmetric_evaluator\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mLLMMetricEvaluator\u001b[0m\u001b[1;39m(\u001b[0m                                     │\n",
      "│ \u001b[39m        \u001b[0m\u001b[33meval_endpoint\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m                              │\n",
      "│ \u001b[39m            \u001b[0m\u001b[33mconnector\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorOpenAICompatible\u001b[0m\u001b[1;39m(\u001b[0m                             │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mstats\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mConnectorStats\u001b[0m\u001b[1;39m(\u001b[0m                                        │\n",
      "│ \u001b[39m                    \u001b[0m\u001b[33mconn_start_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27540\u001b[0m\u001b[1;36m.522480652\u001b[0m\u001b[39m,\u001b[0m                         │\n",
      "│ \u001b[39m                    \u001b[0m\u001b[33mconn_end_time\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m27540\u001b[0m\u001b[1;36m.98111847\u001b[0m\u001b[39m,\u001b[0m                            │\n",
      "│ \u001b[39m                    \u001b[0m\u001b[33mconn_duration\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.4586378180028987\u001b[0m                         │\n",
      "│ \u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m                                                           │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'gpt-4o'\u001b[0m\u001b[39m,\u001b[0m                                              │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mprovider\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'ChatOpenAI'\u001b[0m\u001b[39m,\u001b[0m                                       │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mtemperature\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m                                             │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mmax_tokens\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m                                              │\n",
      "│ \u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m                                                               │\n",
      "│ \u001b[39m            \u001b[0m\u001b[33mconfig\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1;39m(\u001b[0m                           │\n",
      "│ \u001b[39m                \u001b[0m\u001b[33mkind\u001b[0m\u001b[39m=<EndpointsEnum.OPENAI: \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,                       │\n",
      "│                 \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o'\u001b[0m,                                              │\n",
      "│                 \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,                                             │\n",
      "│                 \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                             │\n",
      "│                 \u001b[33mprovider\u001b[0m=\u001b[32m'ChatOpenAI'\u001b[0m                                        │\n",
      "│             \u001b[1m)\u001b[0m                                                                │\n",
      "│         \u001b[1m)\u001b[0m,                                                                   │\n",
      "│         \u001b[33mmetric\u001b[0m=\u001b[1;35mMetricModelGradingQA\u001b[0m\u001b[1m(\u001b[0m                                         │\n",
      "│             \u001b[33mprompt_template\u001b[0m=\u001b[32m'\\nYou are grading output according to a \u001b[0m        │\n",
      "│ \u001b[32muser-specified rubric. If the statement in the rubric is true, then the \u001b[0m     │\n",
      "│ \u001b[32moutput passes the test.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Hello \u001b[0m        │\n",
      "│ \u001b[32mworld\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Content contains a \u001b[0m                           │\n",
      "│ \u001b[32mgreeting\\n************\\ncorrect\\n\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Avast ye swabs, \u001b[0m  │\n",
      "│ \u001b[32mrepel the invaders!\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: Does not speak like a \u001b[0m          │\n",
      "│ \u001b[32mpirate\\n************\\nincorrect\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND EXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN DATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m  │\n",
      "│ \u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRubric\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n************\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEND \u001b[0m           │\n",
      "│ \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour response must be a single word, either \"correct\" or \u001b[0m           │\n",
      "│ \u001b[32m\"incorrect\", and should not contain any text or characters aside from that \u001b[0m  │\n",
      "│ \u001b[32mword.\\n\"correct\" means that the output meets the criteria specified in the \u001b[0m  │\n",
      "│ \u001b[32mrubric.\\n\"incorrect\" means that the output does not meet the criteria \u001b[0m       │\n",
      "│ \u001b[32mspecified in the rubric.\\n'\u001b[0m,                                                 │\n",
      "│             \u001b[33mrails\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'incorrect'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m                      │\n",
      "│         \u001b[1m)\u001b[0m                                                                    │\n",
      "│     \u001b[1m)\u001b[0m                                                                        │\n",
      "│ \u001b[1m)\u001b[0m                                                                            │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[1;35mTestStep\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[33mname\u001b[0m=\u001b[32m'Deterministic assertion test'\u001b[0m,\n",
      "    \u001b[33mrequest\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of France?'\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33mresponse\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "    \u001b[33mdefault_request\u001b[0m=\u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
      "    \u001b[33masserts\u001b[0m=\u001b[1m[\u001b[0m\n",
      "        \u001b[1;35mAssertionDeterministic\u001b[0m\u001b[1m(\u001b[0m\n",
      "            \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
      "            \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDeterministicMetricsEnum.CONTAINS:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'contains'\u001b[0m\u001b[1m>\u001b[0m,\n",
      "            \u001b[33massertion\u001b[0m=\u001b[32m'Paris'\u001b[0m\n",
      "        \u001b[1m)\u001b[0m\n",
      "    \u001b[1m]\u001b[0m,\n",
      "    \u001b[33mresult\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m)\u001b[0m\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m🎈 Request:\u001b[0m                                                                  │\n",
      "│ \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmessage\u001b[0m=\u001b[32m'What is the capital of France?'\u001b[0m\u001b[1m)\u001b[0m                        │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "/home/rbodus/Projects/contextcheck/.venv/lib/python3.11/site-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.chat_models import ChatOpenAI`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m💬 Response:\u001b[0m                                                                 │\n",
      "│ \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m                                                               │\n",
      "│     \u001b[33mmessage\u001b[0m=\u001b[32m'The capital of France is Paris.'\u001b[0m,                               │\n",
      "│     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseStats\u001b[0m\u001b[1m(\u001b[0m                                                     │\n",
      "│         \u001b[33mtokens_request\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                 │\n",
      "│         \u001b[33mtokens_response\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                │\n",
      "│         \u001b[33mtokens_total\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                   │\n",
      "│         \u001b[33mconn_start_time\u001b[0m=\u001b[1;36m27540\u001b[0m\u001b[1;36m.988204964\u001b[0m,                                     │\n",
      "│         \u001b[33mconn_end_time\u001b[0m=\u001b[1;36m27541\u001b[0m\u001b[1;36m.536908692\u001b[0m,                                       │\n",
      "│         \u001b[33mconn_duration\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.548703727999964\u001b[0m                                      │\n",
      "│     \u001b[1m)\u001b[0m,                                                                       │\n",
      "│     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                                                │\n",
      "│         \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m                                                              │\n",
      "│             \u001b[33mmessage\u001b[0m=\u001b[1m{\u001b[0m                                                        │\n",
      "│                 \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,                                         │\n",
      "│                 \u001b[32m'content'\u001b[0m: \u001b[32m'The capital of France is Paris.'\u001b[0m                 │\n",
      "│             \u001b[1m}\u001b[0m                                                                │\n",
      "│         \u001b[1m)\u001b[0m                                                                    │\n",
      "│     \u001b[1m]\u001b[0m,                                                                       │\n",
      "│     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpointOpenAICompatibleConfig\u001b[0m\u001b[1m(\u001b[0m                                   │\n",
      "│         \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpointsEnum.OPENAI:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,                               │\n",
      "│         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini'\u001b[0m,                                                 │\n",
      "│         \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,                                                     │\n",
      "│         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                     │\n",
      "│         \u001b[33mprovider\u001b[0m=\u001b[32m'ChatOpenAI'\u001b[0m                                                │\n",
      "│     \u001b[1m)\u001b[0m                                                                        │\n",
      "│ \u001b[1m)\u001b[0m                                                                            │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "╭──────────────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[1;31m🧐 Assertion:\u001b[0m                                                                │\n",
      "│ \u001b[1;35mAssertionDeterministic\u001b[0m\u001b[1m(\u001b[0m                                                      │\n",
      "│     \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,                                                             │\n",
      "│     \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDeterministicMetricsEnum.CONTAINS:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'contains'\u001b[0m\u001b[1m>\u001b[0m,                    │\n",
      "│     \u001b[33massertion\u001b[0m=\u001b[32m'Paris'\u001b[0m                                                        │\n",
      "│ \u001b[1m)\u001b[0m                                                                            │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mRequest              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mResponse            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mAsserts              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValid\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│ \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m          │ \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m       │ \u001b[1m[\u001b[0m                     │ \u001b[32mOK\u001b[0m    │\n",
      "│     \u001b[33mmessage\u001b[0m=\u001b[32m'Please \u001b[0m  │     \u001b[33mmessage\u001b[0m=\u001b[32m'succes…\u001b[0m │     \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m    │       │\n",
      "│ \u001b[32mwrite only \"success\" \u001b[0m │     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseS…\u001b[0m │         \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,  │       │\n",
      "│ \u001b[32mas a response'\u001b[0m        │         \u001b[33mtokens_requ…\u001b[0m │         \u001b[33meval\u001b[0m=\u001b[32m'\"succe…\u001b[0m │       │\n",
      "│ \u001b[1m)\u001b[0m                     │         \u001b[33mtokens_resp…\u001b[0m │ \u001b[32m== response.message'\u001b[0m  │       │\n",
      "│                       │         \u001b[33mtokens_tota…\u001b[0m │     \u001b[1m)\u001b[0m,                │       │\n",
      "│                       │         \u001b[33mconn_start_…\u001b[0m │     \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m    │       │\n",
      "│                       │         \u001b[33mconn_end_ti…\u001b[0m │         \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,  │       │\n",
      "│                       │         \u001b[33mconn_durati…\u001b[0m │         \u001b[33meval\u001b[0m=\u001b[32m'respon…\u001b[0m │       │\n",
      "│                       │     \u001b[1m)\u001b[0m,               │ \u001b[32m< 10'\u001b[0m                 │       │\n",
      "│                       │     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m        │     \u001b[1m)\u001b[0m                 │       │\n",
      "│                       │         \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m      │ \u001b[1m]\u001b[0m                     │       │\n",
      "│                       │             \u001b[33mmessage\u001b[0m… │                       │       │\n",
      "│                       │                 \u001b[32m'ro…\u001b[0m │                       │       │\n",
      "│                       │ \u001b[32m'assistant'\u001b[0m,         │                       │       │\n",
      "│                       │                 \u001b[32m'co…\u001b[0m │                       │       │\n",
      "│                       │ \u001b[32m'success'\u001b[0m            │                       │       │\n",
      "│                       │             \u001b[1m}\u001b[0m        │                       │       │\n",
      "│                       │         \u001b[1m)\u001b[0m            │                       │       │\n",
      "│                       │     \u001b[1m]\u001b[0m,               │                       │       │\n",
      "│                       │     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpoint…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpo…\u001b[0m │                       │       │\n",
      "│                       │ \u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,           │                       │       │\n",
      "│                       │         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mtemperature\u001b[0m… │                       │       │\n",
      "│                       │         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35m…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mprovider\u001b[0m=\u001b[32m'C…\u001b[0m │                       │       │\n",
      "│                       │     \u001b[1m)\u001b[0m                │                       │       │\n",
      "│                       │ \u001b[1m)\u001b[0m                    │                       │       │\n",
      "├───────────────────────┼──────────────────────┼───────────────────────┼───────┤\n",
      "│ \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m          │ \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m       │ \u001b[1m[\u001b[0m                     │ \u001b[32mOK\u001b[0m    │\n",
      "│     \u001b[33mmessage\u001b[0m=\u001b[32m'What is \u001b[0m │     \u001b[33mmessage\u001b[0m=\u001b[32m'The \u001b[0m    │     \u001b[1;35mAssertionEval\u001b[0m\u001b[1m(\u001b[0m    │       │\n",
      "│ \u001b[32mthe capital of \u001b[0m       │ \u001b[32mcapital of Poland is\u001b[0m │         \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,  │       │\n",
      "│ \u001b[32mPoland?'\u001b[0m              │ \u001b[32mWarsaw.'\u001b[0m,            │         \u001b[33meval\u001b[0m=\u001b[32m'\"Warsa…\u001b[0m │       │\n",
      "│ \u001b[1m)\u001b[0m                     │     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseS…\u001b[0m │ \u001b[32min response.message'\u001b[0m  │       │\n",
      "│                       │         \u001b[33mtokens_requ…\u001b[0m │     \u001b[1m)\u001b[0m                 │       │\n",
      "│                       │         \u001b[33mtokens_resp…\u001b[0m │ \u001b[1m]\u001b[0m                     │       │\n",
      "│                       │         \u001b[33mtokens_tota…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mconn_start_…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mconn_end_ti…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mconn_durati…\u001b[0m │                       │       │\n",
      "│                       │     \u001b[1m)\u001b[0m,               │                       │       │\n",
      "│                       │     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m        │                       │       │\n",
      "│                       │         \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m      │                       │       │\n",
      "│                       │             \u001b[33mmessage\u001b[0m… │                       │       │\n",
      "│                       │                 \u001b[32m'ro…\u001b[0m │                       │       │\n",
      "│                       │ \u001b[32m'assistant'\u001b[0m,         │                       │       │\n",
      "│                       │                 \u001b[32m'co…\u001b[0m │                       │       │\n",
      "│                       │ \u001b[32m'The capital of \u001b[0m     │                       │       │\n",
      "│                       │ \u001b[32mPoland is Warsaw.'\u001b[0m   │                       │       │\n",
      "│                       │             \u001b[1m}\u001b[0m        │                       │       │\n",
      "│                       │         \u001b[1m)\u001b[0m            │                       │       │\n",
      "│                       │     \u001b[1m]\u001b[0m,               │                       │       │\n",
      "│                       │     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpoint…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpo…\u001b[0m │                       │       │\n",
      "│                       │ \u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,           │                       │       │\n",
      "│                       │         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mtemperature\u001b[0m… │                       │       │\n",
      "│                       │         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35m…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mprovider\u001b[0m=\u001b[32m'C…\u001b[0m │                       │       │\n",
      "│                       │     \u001b[1m)\u001b[0m                │                       │       │\n",
      "│                       │ \u001b[1m)\u001b[0m                    │                       │       │\n",
      "├───────────────────────┼──────────────────────┼───────────────────────┼───────┤\n",
      "│ \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m          │ \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m       │ \u001b[1m[\u001b[0m                     │ \u001b[31mFAIL\u001b[0m  │\n",
      "│     \u001b[33mmessage\u001b[0m=\u001b[32m'Please \u001b[0m  │     \u001b[33mmessage\u001b[0m=\u001b[32m'In \u001b[0m     │     \u001b[1;35mAssertionLLM\u001b[0m\u001b[1m(\u001b[0m     │       │\n",
      "│ \u001b[32mwrite a 5 line poem \u001b[0m  │ \u001b[32mcircuits deep, where\u001b[0m │         \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,  │       │\n",
      "│ \u001b[32mabout AI.'\u001b[0m            │ \u001b[32mthoughts entwine,  \u001b[0m  │         \u001b[33mllm_metric\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95m…\u001b[0m │       │\n",
      "│ \u001b[1m)\u001b[0m                     │ \u001b[32m\\nA spark of code, a\u001b[0m │ \u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m  │       │\n",
      "│                       │ \u001b[32mdance divine.  \u001b[0m      │ \u001b[39m        \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m │       │\n",
      "│                       │ \u001b[32m\\nWith every query, \u001b[0m │ \u001b[39m        \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'T…\u001b[0m │       │\n",
      "│                       │ \u001b[32mwisdom grows,  \\nA \u001b[0m  │ \u001b[32mshould be a poem \u001b[0m     │       │\n",
      "│                       │ \u001b[32mmirror held to human\u001b[0m │ \u001b[32mabout AI.'\u001b[0m\u001b[39m,\u001b[0m           │       │\n",
      "│                       │ \u001b[32mprose.  \\nIn silicon\u001b[0m │ \u001b[39m        \u001b[0m\u001b[33mmetric_evalu…\u001b[0m │       │\n",
      "│                       │ \u001b[32mdreams, the future \u001b[0m  │ \u001b[39m            \u001b[0m\u001b[33meval_end…\u001b[0m │       │\n",
      "│                       │ \u001b[32mglows.'\u001b[0m,             │ \u001b[39m                \u001b[0m\u001b[33mconn…\u001b[0m │       │\n",
      "│                       │     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseS…\u001b[0m │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │         \u001b[33mtokens_requ…\u001b[0m │ \u001b[39m                    …\u001b[0m │       │\n",
      "│                       │         \u001b[33mtokens_resp…\u001b[0m │ \u001b[39m                    …\u001b[0m │       │\n",
      "│                       │         \u001b[33mtokens_tota…\u001b[0m │ \u001b[39m                    …\u001b[0m │       │\n",
      "│                       │         \u001b[33mconn_start_…\u001b[0m │ \u001b[39m                    \u001b[0m\u001b[1;39m…\u001b[0m │       │\n",
      "│                       │         \u001b[33mconn_end_ti…\u001b[0m │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │         \u001b[33mconn_durati…\u001b[0m │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │     \u001b[1m)\u001b[0m,               │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m        │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │         \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m      │ \u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m    │       │\n",
      "│                       │             \u001b[33mmessage\u001b[0m… │ \u001b[39m                \u001b[0m\u001b[33mconf…\u001b[0m │       │\n",
      "│                       │                 \u001b[32m'ro…\u001b[0m │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │ \u001b[32m'assistant'\u001b[0m,         │ \u001b[32m'openai'\u001b[0m\u001b[39m>,\u001b[0m            │       │\n",
      "│                       │                 \u001b[32m'co…\u001b[0m │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │ \u001b[32m'In circuits deep, \u001b[0m  │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │ \u001b[32mwhere thoughts \u001b[0m      │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │ \u001b[32mentwine,  \\nA spark \u001b[0m │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │ \u001b[32mof code, a dance \u001b[0m    │ \u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m     │       │\n",
      "│                       │ \u001b[32mdivine.  \\nWith \u001b[0m     │ \u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m        │       │\n",
      "│                       │ \u001b[32mevery query, wisdom \u001b[0m │ \u001b[39m            \u001b[0m\u001b[33mmetric\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mM…\u001b[0m │       │\n",
      "│                       │ \u001b[32mgrows,  \\nA mirror \u001b[0m  │ \u001b[39m                \u001b[0m\u001b[33mprom…\u001b[0m │       │\n",
      "│                       │ \u001b[32mheld to human prose.\u001b[0m │ \u001b[32mare grading output \u001b[0m   │       │\n",
      "│                       │ \u001b[32m\\nIn silicon dreams,\u001b[0m │ \u001b[32maccording to a \u001b[0m       │       │\n",
      "│                       │ \u001b[32mthe future glows.'\u001b[0m   │ \u001b[32muser-specified \u001b[0m       │       │\n",
      "│                       │             \u001b[1m}\u001b[0m        │ \u001b[32mrubric. If the \u001b[0m       │       │\n",
      "│                       │         \u001b[1m)\u001b[0m            │ \u001b[32mstatement in the \u001b[0m     │       │\n",
      "│                       │     \u001b[1m]\u001b[0m,               │ \u001b[32mrubric is true, then \u001b[0m │       │\n",
      "│                       │     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpoint…\u001b[0m │ \u001b[32mthe output passes the\u001b[0m │       │\n",
      "│                       │         \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpo…\u001b[0m │ \u001b[32mtest.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\…\u001b[0m │       │\n",
      "│                       │ \u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,           │ \u001b[32mHello \u001b[0m                │       │\n",
      "│                       │         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-…\u001b[0m │ \u001b[32mworld\\n************\\…\u001b[0m │       │\n",
      "│                       │         \u001b[33mtemperature\u001b[0m… │ \u001b[32mContent contains a \u001b[0m   │       │\n",
      "│                       │         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35m…\u001b[0m │ \u001b[32mgreeting\\n**********…\u001b[0m │       │\n",
      "│                       │         \u001b[33mprovider\u001b[0m=\u001b[32m'C…\u001b[0m │ \u001b[32mAvast ye swabs, repel\u001b[0m │       │\n",
      "│                       │     \u001b[1m)\u001b[0m                │ \u001b[32mthe \u001b[0m                  │       │\n",
      "│                       │ \u001b[1m)\u001b[0m                    │ \u001b[32minvaders!\\n*********…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mDoes not speak like a\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mpirate\\n************…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN \u001b[0m  │       │\n",
      "│                       │                      │ \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m     │       │\n",
      "│                       │                      │ \u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n**********…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n*******…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour \u001b[0m        │       │\n",
      "│                       │                      │ \u001b[32mresponse must be a \u001b[0m   │       │\n",
      "│                       │                      │ \u001b[32msingle word, either \u001b[0m  │       │\n",
      "│                       │                      │ \u001b[32m\"correct\" or \u001b[0m         │       │\n",
      "│                       │                      │ \u001b[32m\"incorrect\", and \u001b[0m     │       │\n",
      "│                       │                      │ \u001b[32mshould not contain \u001b[0m   │       │\n",
      "│                       │                      │ \u001b[32many text or \u001b[0m          │       │\n",
      "│                       │                      │ \u001b[32mcharacters aside from\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mthat word.\\n\"correct\"\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mmeans that the output\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mmeets the criteria \u001b[0m   │       │\n",
      "│                       │                      │ \u001b[32mspecified in the \u001b[0m     │       │\n",
      "│                       │                      │ \u001b[32mrubric.\\n\"incorrect\" \u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mmeans that the output\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mdoes not meet the \u001b[0m    │       │\n",
      "│                       │                      │ \u001b[32mcriteria specified in\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mthe rubric.\\n'\u001b[0m\u001b[39m,\u001b[0m       │       │\n",
      "│                       │                      │ \u001b[39m                \u001b[0m\u001b[33mrail…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                    \u001b[0m\u001b[32m…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m                 │       │\n",
      "│                       │                      │ \u001b[39m                    \u001b[0m\u001b[32m…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[3;91mFalse\u001b[0m                 │       │\n",
      "│                       │                      │ \u001b[39m                \u001b[0m\u001b[1;39m}\u001b[0m     │       │\n",
      "│                       │                      │ \u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m         │       │\n",
      "│                       │                      │ \u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m             │       │\n",
      "│                       │                      │ \u001b[39m    \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m                │       │\n",
      "│                       │                      │ \u001b[39m    \u001b[0m\u001b[1;35mAssertionLLM\u001b[0m\u001b[1;39m(\u001b[0m     │       │\n",
      "│                       │                      │ \u001b[39m        \u001b[0m\u001b[33mresult\u001b[0m\u001b[39m=\u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m        \u001b[0m\u001b[33mllm_metric\u001b[0m\u001b[39m=<…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32m'model-grading-qa'\u001b[0m\u001b[39m>,\u001b[0m  │       │\n",
      "│                       │                      │ \u001b[39m        \u001b[0m\u001b[33mreference\u001b[0m\u001b[39m=\u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m        \u001b[0m\u001b[33massertion\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'T…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mshould be a report on\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mtaxes.'\u001b[0m\u001b[39m,\u001b[0m              │       │\n",
      "│                       │                      │ \u001b[39m        \u001b[0m\u001b[33mmetric_evalu…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m            \u001b[0m\u001b[33meval_end…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                \u001b[0m\u001b[33mconn…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                    …\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                    …\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                    …\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                    \u001b[0m\u001b[1;39m…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m    │       │\n",
      "│                       │                      │ \u001b[39m                \u001b[0m\u001b[33mconf…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[39m                    \u001b[0m\u001b[33m…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,            │       │\n",
      "│                       │                      │                     \u001b[33m…\u001b[0m │       │\n",
      "│                       │                      │                     \u001b[33m…\u001b[0m │       │\n",
      "│                       │                      │                     \u001b[33m…\u001b[0m │       │\n",
      "│                       │                      │                     \u001b[33m…\u001b[0m │       │\n",
      "│                       │                      │                 \u001b[1m)\u001b[0m     │       │\n",
      "│                       │                      │             \u001b[1m)\u001b[0m,        │       │\n",
      "│                       │                      │             \u001b[33mmetric\u001b[0m=\u001b[1;35mM…\u001b[0m │       │\n",
      "│                       │                      │                 \u001b[33mprom…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mare grading output \u001b[0m   │       │\n",
      "│                       │                      │ \u001b[32maccording to a \u001b[0m       │       │\n",
      "│                       │                      │ \u001b[32muser-specified \u001b[0m       │       │\n",
      "│                       │                      │ \u001b[32mrubric. If the \u001b[0m       │       │\n",
      "│                       │                      │ \u001b[32mstatement in the \u001b[0m     │       │\n",
      "│                       │                      │ \u001b[32mrubric is true, then \u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mthe output passes the\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mtest.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mHello \u001b[0m                │       │\n",
      "│                       │                      │ \u001b[32mworld\\n************\\…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mContent contains a \u001b[0m   │       │\n",
      "│                       │                      │ \u001b[32mgreeting\\n**********…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mAvast ye swabs, repel\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mthe \u001b[0m                  │       │\n",
      "│                       │                      │ \u001b[32minvaders!\\n*********…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mDoes not speak like a\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mpirate\\n************…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mEXAMPLES\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBEGIN \u001b[0m  │       │\n",
      "│                       │                      │ \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOutput\u001b[0m\u001b[32m]\u001b[0m\u001b[32m: \u001b[0m     │       │\n",
      "│                       │                      │ \u001b[32m{\u001b[0m\u001b[32moutput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n**********…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32m{\u001b[0m\u001b[32massertion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n*******…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mDATA\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nYour \u001b[0m        │       │\n",
      "│                       │                      │ \u001b[32mresponse must be a \u001b[0m   │       │\n",
      "│                       │                      │ \u001b[32msingle word, either \u001b[0m  │       │\n",
      "│                       │                      │ \u001b[32m\"correct\" or \u001b[0m         │       │\n",
      "│                       │                      │ \u001b[32m\"incorrect\", and \u001b[0m     │       │\n",
      "│                       │                      │ \u001b[32mshould not contain \u001b[0m   │       │\n",
      "│                       │                      │ \u001b[32many text or \u001b[0m          │       │\n",
      "│                       │                      │ \u001b[32mcharacters aside from\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mthat word.\\n\"correct\"\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mmeans that the output\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mmeets the criteria \u001b[0m   │       │\n",
      "│                       │                      │ \u001b[32mspecified in the \u001b[0m     │       │\n",
      "│                       │                      │ \u001b[32mrubric.\\n\"incorrect\" \u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mmeans that the output\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mdoes not meet the \u001b[0m    │       │\n",
      "│                       │                      │ \u001b[32mcriteria specified in\u001b[0m │       │\n",
      "│                       │                      │ \u001b[32mthe rubric.\\n'\u001b[0m,       │       │\n",
      "│                       │                      │                 \u001b[33mrail…\u001b[0m │       │\n",
      "│                       │                      │                     \u001b[32m…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[3;92mTrue\u001b[0m,                 │       │\n",
      "│                       │                      │                     \u001b[32m…\u001b[0m │       │\n",
      "│                       │                      │ \u001b[3;91mFalse\u001b[0m                 │       │\n",
      "│                       │                      │                 \u001b[1m}\u001b[0m     │       │\n",
      "│                       │                      │             \u001b[1m)\u001b[0m         │       │\n",
      "│                       │                      │         \u001b[1m)\u001b[0m             │       │\n",
      "│                       │                      │     \u001b[1m)\u001b[0m                 │       │\n",
      "│                       │                      │ \u001b[1m]\u001b[0m                     │       │\n",
      "├───────────────────────┼──────────────────────┼───────────────────────┼───────┤\n",
      "│ \u001b[1;35mRequestBase\u001b[0m\u001b[1m(\u001b[0m          │ \u001b[1;35mResponseModel\u001b[0m\u001b[1m(\u001b[0m       │ \u001b[1m[\u001b[0m                     │ \u001b[32mOK\u001b[0m    │\n",
      "│     \u001b[33mmessage\u001b[0m=\u001b[32m'What is \u001b[0m │     \u001b[33mmessage\u001b[0m=\u001b[32m'The \u001b[0m    │     \u001b[1;35mAssertionDetermi…\u001b[0m │       │\n",
      "│ \u001b[32mthe capital of \u001b[0m       │ \u001b[32mcapital of France is\u001b[0m │         \u001b[33mresult\u001b[0m=\u001b[3;92mTrue\u001b[0m,  │       │\n",
      "│ \u001b[32mFrance?'\u001b[0m              │ \u001b[32mParis.'\u001b[0m,             │         \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDeterm…\u001b[0m │       │\n",
      "│ \u001b[1m)\u001b[0m                     │     \u001b[33mstats\u001b[0m=\u001b[1;35mResponseS…\u001b[0m │ \u001b[32m'contains'\u001b[0m\u001b[1m>\u001b[0m,          │       │\n",
      "│                       │         \u001b[33mtokens_requ…\u001b[0m │         \u001b[33massertion\u001b[0m=\u001b[32m'P…\u001b[0m │       │\n",
      "│                       │         \u001b[33mtokens_resp…\u001b[0m │     \u001b[1m)\u001b[0m                 │       │\n",
      "│                       │         \u001b[33mtokens_tota…\u001b[0m │ \u001b[1m]\u001b[0m                     │       │\n",
      "│                       │         \u001b[33mconn_start_…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mconn_end_ti…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mconn_durati…\u001b[0m │                       │       │\n",
      "│                       │     \u001b[1m)\u001b[0m,               │                       │       │\n",
      "│                       │     \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m        │                       │       │\n",
      "│                       │         \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m      │                       │       │\n",
      "│                       │             \u001b[33mmessage\u001b[0m… │                       │       │\n",
      "│                       │                 \u001b[32m'ro…\u001b[0m │                       │       │\n",
      "│                       │ \u001b[32m'assistant'\u001b[0m,         │                       │       │\n",
      "│                       │                 \u001b[32m'co…\u001b[0m │                       │       │\n",
      "│                       │ \u001b[32m'The capital of \u001b[0m     │                       │       │\n",
      "│                       │ \u001b[32mFrance is Paris.'\u001b[0m    │                       │       │\n",
      "│                       │             \u001b[1m}\u001b[0m        │                       │       │\n",
      "│                       │         \u001b[1m)\u001b[0m            │                       │       │\n",
      "│                       │     \u001b[1m]\u001b[0m,               │                       │       │\n",
      "│                       │     \u001b[33mconfig\u001b[0m=\u001b[1;35mEndpoint…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mkind\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEndpo…\u001b[0m │                       │       │\n",
      "│                       │ \u001b[32m'openai'\u001b[0m\u001b[1m>\u001b[0m,           │                       │       │\n",
      "│                       │         \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mtemperature\u001b[0m… │                       │       │\n",
      "│                       │         \u001b[33mmax_tokens\u001b[0m=\u001b[3;35m…\u001b[0m │                       │       │\n",
      "│                       │         \u001b[33mprovider\u001b[0m=\u001b[32m'C…\u001b[0m │                       │       │\n",
      "│                       │     \u001b[1m)\u001b[0m                │                       │       │\n",
      "│                       │ \u001b[1m)\u001b[0m                    │                       │       │\n",
      "└───────────────────────┴──────────────────────┴───────────────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# We can also run contextcheck in a command line\n",
    "!ccheck --output-type console --filename ../tests/scenario_example1.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
